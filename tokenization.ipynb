{"cells":[{"cell_type":"code","execution_count":null,"id":"04833552-0b19-4efc-a4c6-3862af136f63","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"04833552-0b19-4efc-a4c6-3862af136f63","outputId":"786c022b-d184-48b4-8eaa-6e26a7ec7dd2"},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":10}],"source":["import nltk\n","nltk.download('punkt')\n","\n"]},{"cell_type":"code","execution_count":null,"id":"8033f09b-8281-4ef5-8a89-ca0664c33ecc","metadata":{"id":"8033f09b-8281-4ef5-8a89-ca0664c33ecc"},"outputs":[],"source":["corpus = \"\"\"Hello you all! How are you doing today?\n","I hope today to be a great day for you..\n","Wish you all the best.\n","Have a great day ahead...\n","Sara's\n","\"\"\""]},{"cell_type":"code","source":["#Tokenization\n","#sentence -> paragraphs\n","from nltk.tokenize import sent_tokenize"],"metadata":{"id":"lt3eDtoVVvNE"},"id":"lt3eDtoVVvNE","execution_count":null,"outputs":[]},{"cell_type":"code","source":["documents = sent_tokenize(corpus)"],"metadata":{"id":"5upqRuCwWDtL"},"id":"5upqRuCwWDtL","execution_count":null,"outputs":[]},{"cell_type":"code","source":["type(documents)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RsO1ec0tWi_n","outputId":"11f94411-2fde-4f11-8f63-acc70f61a571"},"id":"RsO1ec0tWi_n","execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["list"]},"metadata":{},"execution_count":18}]},{"cell_type":"code","source":["for sentence in documents:\n","  print(sentence)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0N3-aO47XFdl","outputId":"bc5fbedb-f20e-49b4-c1fb-2fdb43a84015"},"id":"0N3-aO47XFdl","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Hello you all!\n","How are you doing today?\n","I hope today to be a great day for you..\n","Wish you all the best\n"]}]},{"cell_type":"raw","id":"29346206-93f7-483e-84d9-399cd9ffd12c","metadata":{"id":"29346206-93f7-483e-84d9-399cd9ffd12c"},"source":["corpus"]},{"cell_type":"code","source":["#tokenization\n","#paragraph -> words\n","#sentence -> words\n","from nltk.tokenize import word_tokenize"],"metadata":{"id":"V4ZeWdBKXKWS"},"id":"V4ZeWdBKXKWS","execution_count":null,"outputs":[]},{"cell_type":"code","source":["word_tokenize(corpus)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hp_OgpcvXW-N","outputId":"0de80d61-ca72-4c5c-9961-0dbba1f64493"},"id":"hp_OgpcvXW-N","execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['Hello',\n"," 'you',\n"," 'all',\n"," '!',\n"," 'How',\n"," 'are',\n"," 'you',\n"," 'doing',\n"," 'today',\n"," '?',\n"," 'I',\n"," 'hope',\n"," 'today',\n"," 'to',\n"," 'be',\n"," 'a',\n"," 'great',\n"," 'day',\n"," 'for',\n"," 'you',\n"," '..',\n"," 'Wish',\n"," 'you',\n"," 'all',\n"," 'the',\n"," 'best']"]},"metadata":{},"execution_count":21}]},{"cell_type":"code","source":["from nltk.tokenize import wordpunct_tokenize"],"metadata":{"id":"tz1V-ErLXonV"},"id":"tz1V-ErLXonV","execution_count":null,"outputs":[]},{"cell_type":"code","source":["wordpunct_tokenize(corpus)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jdE2V0MWYCqa","outputId":"2eeafa60-1cbb-4300-936e-d084cb22373a"},"id":"jdE2V0MWYCqa","execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['Hello',\n"," 'you',\n"," 'all',\n"," '!',\n"," 'How',\n"," 'are',\n"," 'you',\n"," 'doing',\n"," 'today',\n"," '?',\n"," 'I',\n"," 'hope',\n"," 'today',\n"," 'to',\n"," 'be',\n"," 'a',\n"," 'great',\n"," 'day',\n"," 'for',\n"," 'you',\n"," '..',\n"," 'Wish',\n"," 'you',\n"," 'all',\n"," 'the',\n"," 'best',\n"," '....',\n"," 'Have',\n"," 'a',\n"," 'great',\n"," 'day',\n"," 'ahead',\n"," '...',\n"," 'Sara',\n"," \"'\",\n"," 's']"]},"metadata":{},"execution_count":26}]},{"cell_type":"code","source":["from nltk.tokenize import TreebankWordTokenizer"],"metadata":{"id":"bbKLf0s6YOvH"},"id":"bbKLf0s6YOvH","execution_count":null,"outputs":[]},{"cell_type":"code","source":["tokenizer = TreebankWordTokenizer()\n","tokenizer.tokenize(corpus)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iFZSZq9eYYJ1","outputId":"0c134bbf-7a6a-4306-94a6-34999e7f1e73"},"id":"iFZSZq9eYYJ1","execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['Hello',\n"," 'you',\n"," 'all',\n"," '!',\n"," 'How',\n"," 'are',\n"," 'you',\n"," 'doing',\n"," 'today',\n"," '?',\n"," 'I',\n"," 'hope',\n"," 'today',\n"," 'to',\n"," 'be',\n"," 'a',\n"," 'great',\n"," 'day',\n"," 'for',\n"," 'you..',\n"," 'Wish',\n"," 'you',\n"," 'all',\n"," 'the',\n"," 'best.',\n"," 'Have',\n"," 'a',\n"," 'great',\n"," 'day',\n"," 'ahead',\n"," '...',\n"," \"Sara's\"]"]},"metadata":{},"execution_count":31}]},{"cell_type":"markdown","source":["DIFFERENCE BETWEEN WORD AND WORD_PUNCT AND TREEBANK :\n","\n","WordTokenizer is just a simpler, user-friendly interface that internally uses the TreebankWordTokenizer.\n","TreebankWordTokenizer is the actual engine providing the tokenization logic, with more emphasis on syntactic tokenization based on Treebank standards."],"metadata":{"id":"G-HaU3tYZAsT"},"id":"G-HaU3tYZAsT"}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.4"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}